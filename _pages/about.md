---
permalink: /
title: "Weiyi Xue's Homepage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## 💫About Me

I am currently a second-year M.S.E. student at [GEAI Lab](https://www.embodiment.ai/) of [Tongji University](https://www.tongji.edu.cn/) and advised by [Prof. Guang Chen]. Before this, I obtained the bachelor’s degree in Vehicle Engineering at Tongji University.

My research interests mainly focus on 3D Computer Vision, in my previous work, I have engaged in research spanning point cloud representation learning/registration to NeRF/Gaussian Splatting. In the short term, my focus is on exploring the intersection of generative models and 3D vision, particularly in tasks such as content generation and scene editing. Looking further ahead, I am especially interested in world models and their potential applications, including simulation and integration with vision-language-action (VLA) systems.
&nbsp;


## 🔥News

**[2025/07]**  Invited as a Reviewer for **AAAI**.   
**[2025/05]**  Invited as a Reviewer for **NeurIPS**. 
**[2025/05]**  Started an internship at DJI, machine learning group, Shenzhen, China. 
**[2024/09]**  🎉 One paper on pose-free reconstruction accepted to **NeurIPS 2024**.
**[2024/02]**  🎉 One paper on dynamic scene reconstruction accepted to **CVPR 2024**.   
**[2023/10]**  🎉 One paper on point cloud registration accepted to **WACV 2024**.    
**[2023/06]**  Graduated with a Bachelor's degree from Tongji University, Shanghai, China.    
 
&nbsp;

<!--  **[2025/06] [IROS 2025]** We proposed a novel diffusion-based framework for sparse 4D radar point cloud super-resolution, outperforming **state-of-the-art** baselines in 4D radar point cloud super-resolution and achieving up to **31.7%** improvement in point cloud registration recall rate and **24.9%** improvement in object detection accuracy. [[paper](https://arxiv.org/pdf/2503.17097v2)]   -->
 
<!--  One paper was submitted to IROS 2025. [[slides]] -->
<!-- **[2024/12]** Invited Talk at Princeton University. [[slides]](../files/Talk_princeton_zehan.pdf)    -->
<!-- **[2024/12]** Invited as a Reviewer for ICML. -->
<!-- &nbsp;   -->

## 📝Publications 
<!--<div class='paper-box'><div class='paper-box-image'><img src='..\static\images\LiDAR4D\dynamic_scene.png' alt="lidar4d" width="100%"> -->
<!--</div><div class='paper-box-text' markdown="1"> -->
<!--**LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis**   --> 
<!--**Zehan Zheng**, Fan Lu, Weiyi Xue, Guang Chen, Changjun Jiang.    -->
<!--**CVPR**, 2024   -->
<!--**[[Paper]](https://arxiv.org/abs/2404.02742) &#124; [[Code]](https://github.com/ispc-lab/LiDAR4D) &#124; [[Project Page]] --><!--(https://dyfcalid.github.io/LiDAR4D) &#124; [[Video]](https://www.youtube.com/watch?v=E6XyG3A3EZ8) &#124; [[Talk]]--><!--(https://www.bilibili.com/video/BV1Uy411Y766/?t=10870) &#124; [[Slides]]--><!--(https://drive.google.com/file/d/1Q6yTVGoBf_nfWR4rW9RcSGlxRMufmSXc/view?usp=sharing) &#124; [[Poster]]--><!--(https://drive.google.com/file/d/13cf0rSjCjGRyBsYOcQSa6Qf1Oe1a5QCy/view?usp=sharing)**   --><!--
Differentiable LiDAR-only framework for novel space-time LiDAR view synthesis, which reconstructs dynamic driving scenarios and --><!--generates realistic LiDAR point clouds end-to-end. It also supports simulation in the dynamic scene.  -->

<!--<div class='paper-box'><div class='paper-box-image'><img src='../images/LPR.png' alt="lidarpr" width="50%">   -->
<!--</div><div class='paper-box-text' markdown="1">   -->
<!--**A System and Method for LiDAR Relocalization Based on Fused Semantic Information Descriptors**      -->
<!--**Boyuan Zheng**, Guirong Zhuo, Lu Xiong.      -->
<!--A GNSS-free LiDAR localization solution comprising place recognition and metric localization modules. The system enhances matching success rates by generating virtual point   --><!--clouds and descriptors, achieving indoor localization accuracy within 10 cm.    -->

<!--</div> <img src="../images/R2LDM.gif" width="800" /> -->
<!--</div>  -->

<table style="border: none; border-collapse: collapse;">


<tr style="border-collapse: separate; border-spacing:none;">
  <td style="border-collapse: collapse; border: none;">
    <img src="https://raw.githubusercontent.com/NathanDrake67/zhengby.github.io/master/images/R2LDM.gif" width="600" />
  </td>
  <td style="border-collapse: collapse; border: none;">     
    "<i>R2LDM: An Efficient 4D Radar Super-Resolution Framework Leveraging Diffusion Model</i>"<br>   
    <b>Boyuan Zheng</b>, Shouyi Lu, Renbo Huang, Minqing Huang, Fan Lu, Wei Tian, Guirong Zhuo, Lu Xiong.<br>
    <b> IROS 2025</b>
    <img src="https://raw.githubusercontent.com/mingsun-tse/mingsun-tse.github.io/master/images/pdf_icon.png" width="20" height="20" hspace="5">
    <span>
      <a href="https://arxiv.org/pdf/2503.17097">Arxiv</a>
      <img src="https://raw.githubusercontent.com/NathanDrake67/zhengby.github.io/master/images/youtube1.png" width="20" height="20" hspace="5">
      <a href="https://www.youtube.com/watch?v=p8hqg3TpJgE">Video</a>
    </span><br>
  </td>
</tr>

<tr style="border-collapse: separate; border-spacing:none;">
  <td style="border-collapse: collapse; border: none;">
    <img src="https://raw.githubusercontent.com/NathanDrake67/zhengby.github.io/master/images/LPR.png" width="600" />
  </td>
  <td style="border-collapse: collapse; border: none;">     
    "<i>A System and Method for LiDAR Relocalization Based on Fused Semantic Information Descriptors</i>"<br>   
    <b>Boyuan Zheng</b>, Guirong Zhuo, Lu Xiong.<br>
    <b>Chinese Patent </b> CN202410446778.9, 2024.<br>

  </td>
</tr>

</table>

<!--    <img src="https://raw.githubusercontent.com/mingsun-tse/mingsun-tse.github.io/master/images/pdf_icon.png" width="20" height="20" hspace="5">    -->
<!--    <span><a href="https://arxiv.org/abs/2301.05219">Arxiv</a></span><br>    -->
<!--    <img src="https://raw.githubusercontent.com/mingsun-tse/mingsun-tse.github.io/master/images/github_icon.png" width="20" height="20" hspace="5">    -->
<!--    <span><a href="https://github.com/MingSun-Tse/Why-the-State-of-Pruning-so-Confusing">Code</a></span><br>    -->


## 💻Research Experience
- July 2023 - Present  
  **Research Assistant** - **Tongji Integrated Positioning Lab ([TJ-IP Lab](https://github.com/TJ-IPLab/)), Tongji University**  
  Advisor: [Prof. Lu Xiong](https://auto.tongji.edu.cn/info/1146/6330.htm) and [Prof. Guirong Zhuo](https://auto.tongji.edu.cn/info/1180/6595.htm)         
  Research included: Diffusion Models, LiDAR SLAM, 4D Radar Perception and Super-Resolution

- April 2025 - Present  
  **Research Intern** - **NLP-MM Group, HKUST(GZ)**  
  Advisor: [Prof. Xuming Hu](https://xuminghu.github.io/) and [Dr. Xu Zheng](https://zhengxujosh.github.io/)    
  Research included: MLLMs, Embodied AI, Multimodal Spatial Reasoning 
  
&nbsp;

## 🛠️Engineering Experience
- 2019 - 2022  
  **Tongji University (Formula SAE) [DIAN Racing Team](http://www.dianracing.com/)** ⚡🏎️   
  Aerodynamics Designer  
  Achieve 1st in FSEC 2020  
  Best Design Report Award in FSEC 2020  

- 2021 - 2022  
**Tongji University (Formula SAE) [DIAN Driverless Team](http://www.dianracing.com/)** ⚡🏎️   
  Aerodynamics Designer & Perception Group Member  
  Achieve 3rd in FSAC 2021  
  Best Design Report Award in FSAC 2021 

&nbsp;   

## 🏆Honors and Awards
- Excellent Graduate of Tongji University, 2023
- Outstanding Student of Tongji University, 2021
- First Prize of Tongji University Scholarship (Top 5%), 2021, 2022
- National First Prize in Formula Student Electric China Competition (FSEC), 2020
- Undergraduate Freshman Scholarship of Tongji University (Top 3 in Hebei Province), 2018  

&nbsp;  
